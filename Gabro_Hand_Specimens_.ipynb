{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwVQQX/SkVOQU0G1CYDRCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mo7amed-Fawzi/Application-desktop-Design-hydraulik-of-fish-tank-/blob/main/Gabro_Hand_Specimens_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime, os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "metadata": {
        "id": "qV6_N4RrMqqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TaL08NtaMqhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPbA0Oa0Mqbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LOqD8FLvMqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24754IClMqF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9kOT9NvD7Ka"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense \n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras import optimizers\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = './gabbro_granite_diorite_granodirite/train'\n",
        "validationData = './gabbro_granite_diorite_granodirite/validate'"
      ],
      "metadata": {
        "id": "z_H5X86tEMP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "steps = 1000 \n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "XbfKkglkESqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first': \n",
        "    input_shape = (3, 100, 100) \n",
        "else: \n",
        "    input_shape = (100, 100, 3) "
      ],
      "metadata": {
        "id": "jBsNBYbyETjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape = input_shape, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (2,2), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "BE2iJNP5EVYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "cazBYmUME451"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "2rkkZkqUEYJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.3, zoom_range = 0.3, horizontal_flip = True) "
      ],
      "metadata": {
        "id": "TIYX4-cQEcSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    trainData, \n",
        "    target_size =(100, 100), \n",
        "    batch_size = batch_size, \n",
        "    class_mode ='categorical',\n",
        "    shuffle=True) "
      ],
      "metadata": {
        "id": "NhRVB_D5EfV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1. / 255) "
      ],
      "metadata": {
        "id": "J1yHqzzrEkPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validationData, \n",
        "    target_size =(100, 100), \n",
        "    batch_size = batch_size, \n",
        "    shuffle=False) "
      ],
      "metadata": {
        "id": "FUsCl6ZMEonS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  trainingmodel = model.fit_generator(train_generator, steps_per_epoch = steps // batch_size, epochs = epochs, validation_data = validation_generator, validation_steps = 200 // batch_size, callbacks=[PlotLossesCallback()], verbose=1) \n"
      ],
      "metadata": {
        "id": "WhnrHfJbEtSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save_weights('gabbro_granite_diorite_granodiorite_weights.h5')\n",
        "model.save('gabbro_granite_diorite_granodiorite.h5')\n",
        "\n",
        "train_gabbro_dir = os.path.join(trainData, 'Gabbro')\n",
        "train_granite_dir = os.path.join(trainData, 'Granite')\n",
        "train_diorite_dir = os.path.join(trainData, 'Diorite')\n",
        "train_granodiorite_dir = os.path.join(trainData, 'Granodiorite')\n",
        "\n",
        "validation_gabbro_dir = os.path.join(validationData, 'Gabbro')\n",
        "validation_granite_dir = os.path.join(validationData, 'Granite')\n",
        "validation_diorite_dir = os.path.join(validationData, 'Diorite')\n",
        "validation_granodiorite_dir = os.path.join(validationData, 'Granodiorite')\n",
        "\n",
        "num_gabro_tr = len(os.listdir(train_gabbro_dir))\n",
        "num_granite_tr = len(os.listdir(train_granite_dir))\n",
        "num_diorite_tr = len(os.listdir(train_diorite_dir))\n",
        "num_granodiorite_tr = len(os.listdir(train_granodiorite_dir))\n",
        "\n",
        "num_gabbro_val = len(os.listdir(validation_gabbro_dir))\n",
        "num_granite_val = len(os.listdir(validation_granite_dir))\n",
        "num_diorite_val = len(os.listdir(validation_diorite_dir))\n",
        "num_granodiorite_val = len(os.listdir(validation_granodiorite_dir))\n",
        "\n",
        "total_train = num_gabro_tr + num_granite_tr + num_diorite_tr + num_granodiorite_tr\n",
        "total_val = num_gabbro_val + num_granite_val + num_diorite_val + num_granodiorite_val\n",
        "\n",
        "test_steps_per_epoch = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n"
      ],
      "metadata": {
        "id": "_NNriSK2E-8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict_generator(validation_generator, steps=test_steps_per_epoch)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_classes = validation_generator.classes\n",
        "class_labels = list(validation_generator.class_indices.keys()) \n",
        "\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ],
      "metadata": {
        "id": "adGpUYg-FNbk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}